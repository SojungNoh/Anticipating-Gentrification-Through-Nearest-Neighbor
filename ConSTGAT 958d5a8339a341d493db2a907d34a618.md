# ConSTGAT

# Abstract

<aside>
💡 **TTE : for given route & departure time, estimates travel time**

</aside>

### **Challenging**

1. **Accuracy of Traffic Prediction :** 루트 안의 도로 세그먼트별 교통 속도에 따라 다르다.
    - **Existing ST-GNN :** Spatial / Temporal 정보가 각각 따로 이용되기 때문에 각각의 속성을 최대한 활용하지 못하고 있는 상황
2. **Considering Contextual Info :** 인접 도로와의 관계도 큰 영향을 미친다.
    - **Existing ST-GNN :** Sequential 인코딩만을 이용해 문제를 해결하려고 하지만, 대규모 스케일의 현실 서비스에 적용하기 위해 scale-up하기 어려움.

### Proposal

ConSTAGAT, 위에 언급된 Traffic Prediction(1)과 Contextual Info(2)의 문제를 동시에 해결. Graph Attention Mechanism을 사용하는 ST-GNN 모델. 

(1) Traffic Prediction 차원에서 모델은 시간적, 공간적 데이터 결합해 충분히 활용하도록 고안.

(2) Contextual Info를 처리하기 위해 직접 고안한 Convolution으로 루트의 주변정보 고려함.

이러한 방식으로 TTE는 사전에 병렬적으로 계산될 수 있음. 또한 ConSTGAT는  대규모 현실 데이터로 검증이 되었으며, Baidu Maps를 통해 실전에서 수천만건을 처리하고 있음.

# 1.0  Introduction

### **Challenging**

1. **Accuracy of Traffic Prediction :** 루트 안의 도로 세그먼트별 교통 속도에 좌우된다. 특히 시작점으로부터 떨어진 도로의 경우 예측이 더 어렵다.
    - **Existing ST-GNN :** Spatial / Temporal 정보가 각각 따로 이용되기 때문에 각각의 속성을 최대한 활용하지 못하고 있는 상황
2. **Considering Contextual Info :** 인접 도로와의 관계도 큰 영향을 미친다, 가령 좌회전과 우회전에 걸리는 속도가 다르다던지, 연결 관계가 어떠한가도 큰 영향을 미치게 됨.
    - **Segment-based Approaches :** 각각의 도로 세그먼트들을 독립적으로 계산함. 효율적이긴 하지만 contextual info를 무시하는 방식
    - **End-to-end Approaches :** 루트의 모든 도로 세그먼트를 감안하여 sequence encoding을 하다보니, 엄청난 연산 비용을 필요로 하게 됨.

### Proposal

ConSTAGAT, 위에 언급된 Traffic Prediction(1)과 Contextual Info(2)의 문제를 동시에 해결. 

**(1) Traffic Prediction** 차원에서 모델은 시간적, 공간적 데이터 결합해 충분히 활용하도록 고안. Graph Attention Mechanism을 사용하는 ST-GNN 모델. 

**(2) Contextual Info**를 연산 비용 측Graph Attention Mechanism을 사용하는 ST-GNN 모델. 면에서 효율적으로 처리하기 위해 직접 고안한 Convolution으로 루트의 주변정보 고려함. 또 퍼포먼스를 신장하기 위해 Multi-task Learning도 진행함.

### Contributions

- **Potential Impact :** 산업적 솔루션으로서 end-to-end neural framework 제시. 수천만컨의 요청을 처리하기 위해 처음으로 바이두 맵에 적용함.
- **Novelty :** 시간과 공간의 정보를 밀접하게 활용하기 위해 Spatial-temporal graph attention network를 개발하고 적용했다는점, contextual info를 효율적으로 처리하게 위해 multi-tasking에 convolution을 적용했다는 점에서 새로운 제안을 함.
- **Technical Quality :** 거대한 현실 트래픽 데이터로 성능을 검증했다는 점. 그리고 Baidu Map에 성공적으로 적용해 사용되고 있다는 점에서 실용적이고 robust한 TTE 솔루션이다.

# 2.0  Related Work

## 2.1 Travel Time Estimation

TTE는 크게 두 방향에서 연구가 되었음. Segment-based methods, End-to-end methods

1. **Segment-based methods**
    
    각각의 도로에 대한 예상 소요 시간을 독립적으로 계산해 합산하는 방식으로 매우 효율적임. 하지만 contextual info. 즉, 두 인접한 도로의 연결관계를 무시한다는 단점이 있음.
    
2. **End-to-end methods**
    
    이 방법은 위와 달리 도로 루트 전체를 직접적으로 한번에 계산한다. Contextual Info(교통신호나 좌‧우회전 등)을 포착하기 위해 RNN 구조를 활용하며, Segment-based method 보다 정확도 측면에서 효율적이다. 가령;
    
    - Wang et al. [16] : 도로세그먼트 간의 관계를 Convolution 과 Stacked LSTM으로 해석.
    - Zhang et al. [23] : Contextual Info를 포착하기 위해 bi-directional LSTM 사용.
    - Wang et al. [19] : Wide-Deep-Recurrent 모델 사용.  Wide&Deep 모델과 LSTM의 결합으로, LSTM이 도로의 contextual info를 다룸.
    
    RNN의 구조는 도로세그먼트간의 상관관계를 학습할 수 있지만, 문제는 거대한 스케일의 내비게이션을 만들기에는 연산 비용이 지나치게 크다는 점이 문제. 어떤 루트는 수천개의 세그먼트로 나뉠 수도 있는데, 연산을 미리 할 수 없고 순차적으로 해야 하기 때문에 시간이 지나치게 오래 걸리게 됨. 이러한 부분 때문에 end-to-end 모델은 스케일업 하기 어렵다.
    

제안하는 ConSTGAT는 위 두가지 방법 모두의 장점을 활용하고자 함. 도로 세그먼트의 주행 시간을 각각 동시에 계산한다. Contextual Info를 얻기 위해 convolution을 사용하고, 각각의 도로와 도로 전체에 대한 loss function을 도입한다.

## 2.2 Spatial-Temporal Graph Neural Networks

최근 GNN의 인기가 커지면서, 컴퓨터비전, 자연어철, 추천시스템 등등 다양한 도메인의 문제에  그래프 구조를 적용하고 있음. 이에 따라 시간과 공간 정보를 동시 다루는 교통 문제에도 GNN이 적용되기 시작했고, 이는 STGNN이라 불림.

기존 GNN과 STGNN의 차이는 시간과 공간 정보를 활용한다는 점. STGNN은 우선 지리적 정보를 GCN(Graph Convolutional Network)나 GAT(Graph Attention Network)으로 인코딩하고, 시간적 정보를 LSTM, CNN, Attention Mechanism을 활용해 처리함.

하지만 기존 STGNN의 단점은 시간과 공간 정보를 독립적으로 다룬다는 점. 시공간의 연관관계를 다루지는 않는 다는 점이 한계. 이 문제를 해결하고자, 지리적 정보와 시간적 정보를 동시에 인코딩하는 새로운 GNN을 제안하게 되었음.

# 3.0  Preliminary

이 섹션에서는 TTE문제를 규정하고, ConSTGAT 프레임워크에 활용된 개념들을 소개한다.

## 3.1 Problem Definition

- $\mathcal{G}=(\mathcal{L}, \mathcal{E})$
    - $\mathcal{G}$ : **Road Network**
    - $\mathcal{L}$ : Link set or Road segment, where $l \in \mathcal{L}$
    - $\mathcal{E}$ : Edge set, where $e_{ij}\in\mathcal{E}$, connecting link $l_i$ and $l_j$ when sharing same junction.
- $r=[l_1, l_2, ..., l_m]$
    - $r$ : **Route**, containing $m$ number of links. Navigation creates several candidates of it.
- $req=(r,s)$
    
    Task of TTE is to estimate the travel time $y$ of a request $req$.
    
    - $r$ : Route
    - $s$  : Departure Time
- $\mathcal{D}=\{(req^{(i)},y^{(i)})\}^n_{i=1}$
    - $\mathcal{D}$ : Dataset
    - $n$ : The number of requests in the dataset.
    - $y^{(i)}$ : Ground-truth travel time for request $req^{(i)}$
    - $y^{(i)}=\sum^{m^{(i)}}_{j=1}y_j^{(i)}$
    - $y_j^{(i)}$ : The travel time of the $j$-th link $l_j^{(i)}$ in route $r^{(i)}$, of the request $req^{(i)}$

## 3.2 Feature Extraction

학습을 위해 추출하는 특징들은 Road Network / Historical Traffic Conditions / Background Info 세 가지가 있다.

1. **Road Network**
    
    Road Network는 링크 사이의 관계를 표현한다. 다음 여덟가지가 feature로 추출된다.
    
    | ID | Length | Width | # of lanes |
    | --- | --- | --- | --- |
    | Type | Speed Limit | Type of Crossing | Kind of Traffic Light |
    
    추가적으로 링크 간의 지리적 관계를 표현하기 위해 graph structure을 활용했다.
    
2. **Historical Traffic Conditions**
    
    과거 데이터로부터 주어진 링크 $l$에 대한 타임 슬롯 $t$ 의 평균/중앙값을 feature로 추출한다. 이 연구에서 사용되는 타임 슬롯은 5분이다.
    
3. **Background Information**
    
    TTE는 수 많은 다른 배경 정보에 영향을 받을 수 있다. 가령 출발시간이 러시아워이거나, 주중이거나, 혹은 다른 시간 관련 특징에 따라 다른 결과를 낼 수 있기 때문이다. 따라서 이러한 시간 관련 특징도 추출하게 된다.
    
    - $x_i^{(B)}$ : $i$-th Link의 배경정보

# 4.0  ConSTGAT

## 4.1 Framework

크게 두 정보 *Contextual Information*, *Traffic Prediction* 모듈로 이루어져 있으며, 이 모듈을 합친 모듈을 *Integration*이라 한다.

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled.png)

- ***Traffic Prediction 모듈 :*** 시간과 공간 데이터의 관계를 밀접하게 포착하기 위한 모듈로, 이 논문에서 제시하는 새로운 방법으로 spatial-temporal graph attention network를 활용함.
- ***Contextual Information 모듈 :***  Contextual Info를 잡아내는 데 활용되는 모듈로, 인접한 링크의 관계를 포착하기 위해 Convolution을 활용.
- ***Integration 모듈 :*** Contextual Info를 잡아내는 데 활용되는 모듈로, Multi-task Learning을 활용해 퍼포먼스를 향상시키기 위한 모듈.

## 4.2 Traffic Prediction Module

한 링크의 교통 상황은 해당 링크의 과거 이력과 주변 이웃 링크와 큰 상관관계가 있습니다. 가령 한 링크가 교통량이 많아지면 주변 노드들의 교통량도 잇따라 많아지는 상황 같은 것이지요. 이러한 상황에 대한 예측을 하기 위한 방법으로 STGNN이 활용되었지만, 공간정보와 시간정보가 개별적으로 활용된다는 단점이 있습니다. 이 논문은 이 정보들을 효율적으로 활용하기 위해, 공간정보와 시간정보를 동시에 다루는 방법인 Spatial-temporal graph attention network를 제안합니다. 

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%201.png)

Traffic Prediction 모듈은 교통 히스토리, 그래프 $\mathcal{G}$, 출발시간 $s$ 를 인풋으로 받아 앞으로의 교통상황을 예측합니다. 여기서 시간-공간 관계를 포착하기 위해 Graph attention network의 일종인 3D-attention mechanism 을 사용합니다.

1. $[C^{s-T_h}, \cdot\cdot\cdot, C^{s-1};\mathcal{G}] \rightarrow [\hat C^{s}, \hat C^{s+1}, \cdot\cdot\cdot, \hat C^{s+T_f-1}]$
    - $C^t$ : Traffic conditions observed on graph $\mathcal{G}$ at time slot $t$
    - $c^t_l$ : Traffic conditions observed on graph $\mathcal{G}$ at time slot $t$, on link $l$
    - $T_f$ : Number of the predicted future time slots
    - $T_h$ : Number of the historical time slots used to train the model

- **1단계 ) ST-tensor 추출하기 : 시간-공간 관계 표현**
    
    이를 진행하기 위해 우선 Spatial-temporal tensor $X_i^{^{(MST)}}$을 추출합니다.  $X_i^{^{(MST)}}$는 교통 히스토리  $X^{(ST)}_i$, 이웃 링크 특성 $X^{(S)}_i$, 타임슬롯 특성$X^{(T)}$ 행렬을 결합함으로써 얻을 수 있습니다. 세부 내용은 아래를 참조하세요. 
    
    - $X_i^{^{(MST)}}\in\mathbb{R}^{|\mathcal{NB}(l_i)|T_h\times d^{(MST)}}$
        
        New spatial-temporal matrix by merging $X^{(ST)}_i$, $X^{(S)}_i$, $X^{(T)}$
        
        $d^{(MST)}$$=d^{(ST)}+d^{(S)}+d^{(T)}$
        
        - $\mathcal{NB}(l_i)=\{l_j|e_{ij}\in\mathcal{E}\}$ : Neighbor set of link $l_i$
        - $X_i^{(ST)}\in\mathbb{R}^{|\mathcal{NB}(l_i)|T_h\times d^{(ST)}}$ : Historical traffic conditions matrix
            - $|\mathcal{NB}(l_i)|$ : Number of neighbors for link $l_i$
            - $T_h$ : Number of the historical time slots used to train the model
            - $d^{(ST)}$ : Dimension of the features
            - $X^{(ST)}_{i, (j-1)T_h+k}$ : Traffic condition of the $k$-th time slot of the $j$-th neighbor of link $i$, with $j\in[1,\mathcal{NB(l_i)}]$ and $k \in [1, T_h]$
        - $X_i^{(S)}\in\mathbb{R}^{|\mathcal{NB}(l_i)|\times d^{(S)}}$ : Features of the neighbor links
            - $d^{(S)}$ : Dimension of the features for spatial information
        - $X^{(T)}\in\mathbb{R}^{T_h\times d^{(T)}}$ : Features of the historical time slots
            - $d^{(T)}$ : Dimension of the features for temporal information
    
    조금 더 구체적으로 들어가자면, $k$번째 타임슬롯에서 링크 $i$의 이웃인 링크 $j$의 시공간 행렬은 Concat을 통해 구현될 수 있고, 이를 통해 기존의 행렬이 3D-tensor로 변환됩니다. 이 3D-tensor는 $l_i$에서의 교통상황을 예측할 spatio-temporal tensor (ST-tensor)를 만들기 위해서 반드시 가져야 할 형태이기도 합니다.
    
    1. $X^{(MST)}_{i,j,k}= \mathbf{Concat}(X^{(ST)}_{i, (j-1)T_h+k},\; X_{ij}^{(S)},\;X_{k}^{(T)})$ $, j\in[1, \mathcal{NB}(l_i)],k\in[1,T_h]$
        - $X^{(MST)}_i$$\in\mathbb{R}^{|\mathcal{NB}(l_i)|\times T_h\times d^{(ST)}}$
- **2단계 ) Attention Mechanism으로 시간과 공간의 연관 정보 추출하기 : 교통상황 파악**
    
    이 단계에선 시간과 공간 관계를 포착하기 위해 새로운 3D-attention 메커니즘을 제안하고 있습니다. 어텐션 메커니즘을 수행하려면 key, value, query가 필요한데요. 각각 다음과 같습니다.
    
    - Query : Contextual Information $x^{(CI)}_{i,w}$ , Background Information $x^{(B)}_i$
    - Key : ST-tensor $X^{(MST)}_{i,j,k}$
    - Value : ST-tensor $X^{(MST)}_{i,j,k}$
    
    이를 바탕으로 3D-attention은 다음과 같이 전개됩니다.
    
    1. $Q_i=\mathbf{Dense}(\mathbf{Concat}(x^{(CI)}_{i,w}, x^{(B)}_{i}))$
    2. $K_{i,j,k}=\mathbf{Dense}(X^{(MST)}_{i,j,k})$
    3. $V_{i,j,k}=\mathbf{Dense}(X^{(MST)}_{i,j,k})$
    4. $f(Q_i, K_{i,j,k}) = \frac{Q_i^T\cdot K_{i,j,k}}{\sqrt{d^{(H)}}}$
        - $d^{(H)}$ : Hidden size of attention mechanism
    5. $\alpha(Q_i, K_{i,j,k}) = \frac{exp(f(Q_i, K_{i,j,k}))}{\sum_{j',k'}exp(f(Q_i, K_{i,j',k'}))}$
    6. $Attention(Q_i, K_i, V_i)=\sum_{j,k}\alpha(Q_i,K_{i,j,k})V_{i,j,k}$
    
    이에 따라 링크 $l_i$에서 지난 교통 히스토리와 query간의 관계는 8번 식에 따라  $x_i^{(TC)}=Attention(Q_i, K_i, V_i)$ 로 정리될 수 있습니다. 따라서 이렇게 3D-attention으로 구현한 GNN을 “3DGAT”라 부릅니다.
    
- **3단계 ) Masking Mechanism으로 Robustness 개선하기**
    
    이러한 모델을 학습하는 경우, 종종 약한 시그널 때문에 교통 상태 정보가 사라지게 되는 경우도 있는데요, 이러한 문제를 해결하고 모델의 robustness를 개선하기 위해 이 논문은 Masking Mechanism도 제안합니다. Masking은 NLP 분야에서 성능이 입증된 바 있습니다.
    
    학습단계에서 랜덤하게 과거 교통 컨디션의 10%에 mask를 씌우는 것인데, 보다 구체적으로는 $req=(r,s)$에서 $c_i^t \;(i\in[1,m], t\in[s-T_h,s-1])$의 10%를 제로 벡터로 만드는 것입니다. 이렇게 뉴럴네트워크에 노이즈를 넣어 과적합을 방지하고, 모델의 generalization을 개선하려는 목적입니다.
    

## 4.3 Contextual Information Module

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%202.png)

이 섹션에서는 : Convolution을 통해 주변 정보를 효율적으로 학습하는 Contextual Information Module과, Multi-task Learning을 하는 Integration Module을 다룹니다. 

- **1단계 )** **Contextual Information Module : 주변정보 인코딩**
    
    여기에서 주변정보, Contextual Information이라 함은, 두 링크 사이의 각도, 중심도로와 보조도로와의 관계 등을 말합니다. 이 주변정보는 travel time을 예측하는데 중요한 역할을 합니다. 여기에서는 루트에 포함된 모든 링크의 travel time을 예측하는데요, 그럴 때 루트 안의 주변 노드의 정보를 활용함으로써 예측 성능을 높이는 식입니다. 주변 노드는 sub-path라고 정의되며, 다음과 같이 표현합니다.
    
    - $p_{i,w}=[l_{i-w},\cdot\cdot\cdot, l_{i-1}, l_{i}, l_{i+1},\cdot\cdot\cdot,l_{i+w}]$
    
    여기에서 $i$는 계산할 대상 링크이고, $w$는 주변정보를 고려하는 window 크기를 말합니다. 가령, $w=0$ 이라면, 링크 $i$의 정보만을 고려하는 것 입니다. 이런 경우에는 segment-base method와 같은 설정이 되겠습니다. 만약 $w\rightarrow \infin$ 이라면, 루트 $r$의 모든 링크들이 고려 대상이 되고, 이는 vanilla end-to-end method와 같은 설정이 되겠습니다.
    
    이처럼 이 모델은 특정 링크의 travel time은 주변 노드의 상황으로부터 영향을 받는다는 가정을 깔고 있는데, 이런 상황에서 CNN은 주변 정보, 즉 지역적 의존성을 수집하기 효율적인 방법입니다. 다음과 같이 $l_i$의 주변 정보를 인코딩 합니다.
    
    1. $x^{(CI)}_{i,w}=\mathbf{Dense}(\mathbf{Concat}(\mathbf{Emb}(l_{i-w}),\cdot\cdot\cdot,\mathbf{Emb}(l_{i}),\cdot\cdot\cdot,\mathbf{Emb}(l_{i+w})))$
    
    이렇게 도출된 주변 정보 인코딩은 앞서 살펴보았던 Traffic Prediction Module의 쿼리와 Integration Module에 사용됩니다.
    
- **2단계 ) Integration Module : Travel Time 예측**
    
    이제 최종 예측을 위한 모듈인 Integration Module만 남았습니다. 이 단계에서는 Traffic Prediction Module $x^{(TC)}_{i}$, Context Information Module $x^{(CI)}_{i,w}$, Background Information $x^{(B)}_{i}$ 이 세개로부터 인풋을 받습니다. 이렇게 받은 인풋은 그림과 같이 Concatenation을 거쳐 Multiple Fully-connected Layer을 지나 루트안에 있는 모든 링크의 travel timed을 예측합니다.
    
    1. $\hat y_i=\mathbf{MLP}(\mathbf{Concat}(x_{i,w}^{(CI)},x_{i}^{(B)},x_{i}^{(TC)}))$
    
    각각 계산된 링크들의 travel time을 모두 더해 전체 루트의 travel time을 구하므로써 끝이 납니다.
    
    1. $\hat y=\sum^m_{i=1}\hat y_i$
    
- **3단계 ) Loss 계산**
    
    이렇게 도출된 예측 Travel time을 기반으로 Loss function을 구축하게 되는데요. 서로 다른 방식인 Segment-based method와 End-to-end method의 장점을 한번에 녹이기 위해, 지금까지 계산한 값에 대해 각각의 방식에 따른 Loss Function을 적용합니다.
    
    Segment-based method 차원에서 사용한 손실함수는 Huber Loss로, 루트 안에 포함된 모든 각각의 링크의 travel time에 대해 계산합니다. 한편, End-to-end method 차원에서 사용한 손실함수는 APE로, 합산된 루트의 travel time에 대해 계산합니다. 이 두 방식을 한번에 담은 손실함수는 다음과 같고, 이 손실함수를 최소화 하는 방향으로 학습이 진행됩니다.
    
    1. $L=\frac{1}{n}\sum^n_{i=1}(\frac{1}{m^{(i)}}\sum^{m^{(i)}}_{j=1}L_{link}(\hat y_j^{(i)},y_j^{(i)})+L_{route}(\hat y^{(i)},y^{(i)}))$
- **4단계 ) 현실 적용**
    
    Baidu Maps의 네비게이션은 하루에 몇백만건을 처리해야 하는데, 이런 상황에서는 반응 시간이 매우 중요합니다. 하지만 대부분 높은 정확도를 가진 모델들은 연산시간이 오래 걸리는 End-to-end 방식을 사용하기 때문에 어플리케이션을 스케일업 하기가 어려운 상황입니다.
    
    연산시간을 줄이기 위해 이 논문에서는 segment-based method의 방법 일부를 차용하는데요. 우선 그래프 안에 있는 모든 링크에 대해 서로 다른 sub-path와 출발 시간 타임슬롯을 병렬로 계산해 저장해 둡니다. 그런 다음 어떤 요청이 들어오면, 저장해둔 테이블에서 요청된 링크에 해당하는 상황을 찾아 합산해 예측시간을 리턴하는 것입니다. 이렇게 병렬적으로, 미리 계산해둠으로써 현실에 맞게 스케일 업 할 수 있게 됩니다.
    

# 5.0  Experiments

### 5.1 Experimental Settings

- **사용한 데이터셋**
    - 2019년 7월 21일부터 8월 31일까지 Baidu Map의 Taiyuan, Hefei, Huizhou 세 도시의 로그로부터 샘플링한 것.
    - 첫 4주 간의 데이터는 Training 용으로, 마지막 1주 간의 데이터는 Testing 용으로 분리했음.
- **평가지표**
    - 회귀 문제에 널리 활용되는 평가 지표인 MAPE / MAE / RMSE를 사용한다.
- **알고리즘 세팅**
    - 모든 Attribute의 Embedding Sizes = 8
    - ***Traffic Prediction Module***
        - $T_h=12$, Traffic conditions historical time slot
        - $d^{(H)}=32$ , Hidden size of the 3D-attention mechanism
    - ***Contextual Information Module***
        - $Number \;of\; filters=32$
        - $w=1$, Default Window Size
    - ***Integration Module***
        - Two-layer MLP
        - Output size of the first fully-connected layer = 64
        - $T_f=12$, Time travels of the link of future times slots
    

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%203.png)

### 5.2 Methods for Comparison

| Baselines | Description | Etc |
| --- | --- | --- |
| AVG | Average traffic speeds of 2016.
 |  |
| DeepTravel | (1) Extract spatial / temporal feature
(2) Employ bi-directional LSTM

Hidden size of bi-LSTM : 32 |  |
| STANN | (1) Encode spatial info by graph Attention
(2) Encode temporal info by LSTM & Attention

Hidden size of GNN : 32
Hidden size of LSTM : 32

* But not proactical becauseit consider all links! Here we only consider neighbor links. | Deploy GNN to  estimate travel times of the links rather than that of entire route. |
| DCRNN | (1) Capture spatial dependency by GCN
(2) Capture temporal dependency by LSTM

Hidden size of GNN : 32
Hidden size of LSTM : 32 | Deploy GNN to  estimate travel times of the links rather than that of entire route. |
| GAT+Attention | Developed Model
(1) Aggregate spatial info by graph attntn network
(2) Aggregate temporal info by attntn mechanism
→ Consider each independently

Hidden size of GNN : 32
Hidden size of Attention Mech : 32 | Deploy GNN to  estimate travel times of the links rather than that of entire route. |
| 3DGAT | Developed Model
(1) Aggregate spatial info by graph attntn network
(2) Aggregate temporal info by attntn mechanism
→ Consider each simultaneously

Hidden size of GNN : 32
Hidden size of Attention Mech : 32 | Deploy GNN to  estimate travel times of the links rather than that of entire route. |

### 5.3 Experimental Results

**5.3.1 Overall Evaluation**

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%204.png)

ConSTGAT 는 모든 데이터셋에 대해, 다른 모든 모델의 성능을 압도한다!

**5.3.2 Spatial-Temporal Graph Neural Networks**

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%205.png)

일반적인 STGNN은 전체 루트를 예측하기보다, 특정 링크를 예측하는데 최적화 되어 있음. 따라서 STGNN모델들간에 링크를 예측하는 실험도 진행. 마찬가지로 ConSTGAT가 다른 모델을 압도하고 있음.

*3DGAT는 이 실험을 위해 최적화된 $w=0$인 ConSTGAT의 또 다른 버전.

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%206.png)

Spatial 정보와 Temporal 정보간의 상관관계를 보기 위해 Attention Weight의 행렬을 그려 보았다. 특정 링크 $l$과 자신을 포함한 9개의 이웃들을 5분의 타임슬롯 위에서 비교한다. 다이어그램에 대한 설명은 다음과 같다.

- ROW : itself-자기 자신 | downstream 앞으로 갈 링크 | upstream 지나온 링크 | other 나머지
- COLUMN : 첫번째 열 - 최신 타임슬롯 | 마지막 열 - 가장 나중 타임슬롯
- COLOR : 어두운 색 - 링크 $l$에 적합함 | 옅은 색 - 링크 $l$에 적합하지 않음

분석결과는

(1) Downstream 링크들이 링크 $l$에 더 적합한 것으로 나옴.

(2) 교통 기록이 더 많거나, 더 긴 travel time을 가진 링크가 예측에 더 중요한 역할을 한다.

**5.3.3 Contextual Information**

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%207.png)

한 루트에서 contextual information의 영향을 분석해보자. 이 분석을 하기 위해 ConSTGAT의 contextual window size를 바꿔가며 travel time을 예측해 보았다.

- $w=0$ : Segment-based method와 똑같다. 계산 시 어떠한 주변 정보도 고려하지 않는다.
- $w>0$ : 클 수록 주변 링크의 정보를 활용해 계산한다.

결과적으로 주변 정보를 활용할수록 RMSE가 감소하는 것으로 보아 모델의 퍼포먼스가 개선되는 것으로 확인되었다. (단 Hefei의 경우 딱히 그런것 같진 않다.)

**5.3.4 Robustness**

![Untitled](ConSTGAT%20958d5a8339a341d493db2a907d34a618/Untitled%208.png)

Masking이 모델의 robustness를 개선시키는지 확인해보자. 

- Train mask rate = 0% : 모든 정보를 알되, 일부 노이즈가 있는 정도
- Train mask rate = 100% : 모든 기존 교통 컨디션은 알지 못하고, contextual info와 background info만 있는 상태

결과적으로 Train mask rate 10%인 상황이 아닌상황보다 RMSE가 전반적으로 낮게 나오는 것을 확인할 수 있다. 따라서 Masking은 모델의 robustness를 개선하는데 도움이 된다.

# 6.0  Conclusion

이 논문에서는 연산이 효율적인 end-to-end STGNN모델인 ConSTGAT를 제안한다. 기존 모델들이 traffic prediction(1) 과 contextual information(2) 차원에서 가졌던 문제를 해결하기 위해 :

(1) Spatial / Temporal 의 연관성을 깊게 가져간 3D-attention 메커니즘을 개발했다.

(2) 주변 정보를 효율적으로 습즉하기 위해 루트의 정보를 convolution을 통해 습득했고, 나아가 퍼포먼스를 개선하기 위해 Multi-task Learning을 도입했다.

이러한 방법으로, Segment-based 방법에서 힌트를 얻어, 각각의 링크에 대한 travel time을 계산을 동시에 그리고 미리 계산하는 식으로 총 travel time을 예측했다.

거대 스케일의 현실 데이터를 활용해 식험을 수행했으며, 그것을 통해 ConSTGAT의 우수성을 증명했다. 또한 ConSTGAT는 Baidu Map에 실제로 사용되는 알고리즘이기 때문에 실용적이며 안정적인 방법론이라고 할 수 있다.